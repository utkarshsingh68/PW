{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "\n",
        "Ans\n",
        "\n",
        "Simple Linear Regression (SLR) is a statistical method used to find the relationship between one independent variable and one dependent variable. It shows how one variable affects another by fitting a straight line to the data. The equation of SLR is ( Y = a + bX ), where Y is the dependent variable, X is the independent variable, a is the intercept, and b is the slope. The main purpose of Simple Linear Regression is to understand the relationship between two variables and to predict the value of the dependent variable based on the independent variable. For example, it can be used to predict exam marks based on the number of hours studied."
      ],
      "metadata": {
        "id": "VGwqbbbZiwD_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "Ans\n",
        "\n",
        "The key assumptions of Simple Linear Regression are important to ensure that the model gives accurate and reliable results. First, there should be a **linear relationship** between the independent variable (X) and the dependent variable (Y). Second, the **errors (residuals) should be independent**, meaning the data points should not influence each other. Third, the errors should have **constant variance (homoscedasticity)**, which means the spread of residuals should be the same across all values of X. Fourth, the errors should be **normally distributed**, especially for hypothesis testing. Lastly, there should be **no extreme outliers** that can strongly affect the regression line. These assumptions help in making valid predictions and interpretations using Simple Linear Regression.\n"
      ],
      "metadata": {
        "id": "tTRudQLHjlTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: Write the mathematical equation for a simple linear regression model and\n",
        "explain each term.\n",
        "\n",
        "Ans\n",
        "\n",
        "The mathematical equation for a Simple Linear Regression model is:\n",
        "\n",
        "[\n",
        "Y = a + bX\n",
        "]\n",
        "\n",
        "In this equation, **Y** represents the dependent variable, which is the value we want to predict. **X** represents the independent variable, which is the input or predictor variable. **a** is the intercept, which shows the value of Y when X is equal to zero. **b** is the slope of the regression line, which indicates how much Y changes when X increases by one unit. This equation helps us understand the relationship between two variables and make predictions based on that relationship.\n"
      ],
      "metadata": {
        "id": "KUGTKhE4jsCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Provide a real-world example where simple linear regression can be\n",
        "applied.\n",
        "\n",
        "Ans\n",
        "\n",
        "A real-world example of Simple Linear Regression is predicting a student’s exam marks based on the number of hours they study. In this case, the number of hours studied is the independent variable (X), and the exam marks are the dependent variable (Y). By collecting data on different students’ study hours and their corresponding marks, we can create a regression line that shows the relationship between them. Using this model, we can predict how many marks a student might score if they study for a certain number of hours.\n"
      ],
      "metadata": {
        "id": "AC-SIvU2j74h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What is the method of least squares in linear regression?\n",
        "\n",
        "Ans\n",
        "\n",
        "A real-world example of Simple Linear Regression is predicting a student’s exam marks based on the number of hours they study. In this case, the number of hours studied is the independent variable (X), and the exam marks are the dependent variable (Y). By collecting data on different students’ study hours and their corresponding marks, we can create a regression line that shows the relationship between them. Using this model, we can predict how many marks a student might score if they study for a certain number of hours.\n",
        "\n"
      ],
      "metadata": {
        "id": "Cl90ylw2kCsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: What is Logistic Regression? How does it differ from Linear Regression?\n",
        "\n",
        "Ans\n",
        "\n",
        "Logistic Regression is a statistical method used for classification problems, where the dependent variable is categorical, usually binary (such as 0 or 1, Yes or No, True or False). It predicts the probability that a given input belongs to a particular class using a logistic (sigmoid) function, which gives output values between 0 and 1.\n",
        "\n",
        "The main difference between Logistic Regression and Linear Regression is that Linear Regression is used to predict continuous numerical values, while Logistic Regression is used to predict categories or class labels. Linear Regression fits a straight line to the data and can produce any real number as output, whereas Logistic Regression uses an S-shaped curve and limits the output between 0 and 1, which represents probability.\n"
      ],
      "metadata": {
        "id": "0_IqPR64kKpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Name and briefly describe three common evaluation metrics for regression\n",
        "models.\n",
        "\n",
        "Ans\n",
        "\n",
        "Three common evaluation metrics for regression models are **Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R²).**\n",
        "\n",
        "**Mean Absolute Error (MAE)** measures the average of the absolute differences between the actual values and the predicted values. It tells us how far, on average, the predictions are from the true values. Smaller MAE means better model performance.\n",
        "\n",
        "**Mean Squared Error (MSE)** measures the average of the squared differences between actual and predicted values. Since the errors are squared, larger errors are penalized more. A lower MSE indicates a better model.\n",
        "\n",
        "**R-squared (R²)** measures how well the regression model explains the variation in the dependent variable. Its value ranges from 0 to 1. A value closer to 1 means the model explains a larger portion of the variance and fits the data better.\n"
      ],
      "metadata": {
        "id": "OKDXA3GIkSFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: What is the purpose of the R-squared metric in regression analysis?\n",
        "\n",
        "Ans\n",
        "\n",
        "The purpose of the **R-squared (R²)** metric in regression analysis is to measure how well the regression model explains the variation in the dependent variable. It shows the proportion of the total variance in the output variable that is explained by the independent variable(s) in the model. The value of R-squared ranges from 0 to 1. If R² is closer to 1, it means the model fits the data well and explains most of the variation. If it is closer to 0, it means the model does not explain much of the variation. Therefore, R-squared helps us evaluate the goodness of fit of a regression model.\n"
      ],
      "metadata": {
        "id": "CyE_-__LkgYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write Python code to fit a simple linear regression model using scikit-learn\n",
        "and print the slope and intercept.\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1E0aznb5kr3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data (Hours studied vs Marks scored)\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # Independent variable\n",
        "y = np.array([35, 45, 55, 65, 75])            # Dependent variable\n",
        "\n",
        "# Create and fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print slope and intercept\n",
        "print(\"Slope (Coefficient):\", model.coef_[0])\n",
        "print(\"Intercept:\", model.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPt4UTM9kwFU",
        "outputId": "fe189bc3-9a8d-42c1-a883-1c54f42bf4b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Coefficient): 9.999999999999998\n",
            "Intercept: 25.000000000000007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: How do you interpret the coefficients in a simple linear regression model?\n",
        "\n",
        "Ans\n",
        "\n",
        "In a Simple Linear Regression model, the coefficients help us understand the relationship between the independent variable (X) and the dependent variable (Y). The model equation is ( Y = a + bX ). Here, **b** (the slope or coefficient) shows how much the dependent variable changes when the independent variable increases by one unit. If b is positive, it means Y increases as X increases (positive relationship). If b is negative, it means Y decreases as X increases (negative relationship). The **a** (intercept) represents the value of Y when X is equal to zero. Therefore, the coefficients help us understand both the direction and the strength of the relationship between the variables.\n"
      ],
      "metadata": {
        "id": "Xxs2YDHZlFnC"
      }
    }
  ]
}